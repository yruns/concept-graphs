# 研究课题：从场景图构建到语言驱动探索的大模型具身推理方法研究

## 研究背景概述

本研究聚焦于**具身智能（Embodied AI）**领域，核心目标是解决**三维场景信息与大语言模型（LLM）之间的模态鸿沟问题**。当前商业闭源LLM（如GPT-4o、Claude、Gemini）仅支持文本和二维图像输入，无法直接处理点云、三维网格等原生三维数据。本研究旨在设计高效的转换与推理机制，使LLM能够理解和操作三维场景，支持具身智能系统的场景理解与自主决策。

---

## 研究点一：基于时序分段的层次化三维场景图构建方法

### 问题定义

**核心瓶颈**：现有开放词汇三维场景图（如ConceptGraph）呈**扁平结构**，包含场景中所有物体节点及其两两之间的空间关系边。对于真实室内环境：
- 物体数量：数十至数百个
- 关系边数量：以平方级增长
- 序列化后token数量：往往超出LLM的有效上下文窗口（如GPT-4o的128K tokens限制）

**附加问题**：扁平化表示缺乏信息优先级区分，任务无关的细节与关键信息混杂，干扰LLM的注意力分配。

### 研究目标

将扁平的三维场景图重组为**层次化结构**，实现场景信息的高效组织与按需加载，使LLM能够在有限上下文窗口内高效处理大规模场景信息。

### 技术方案

#### 模块1：基于探索轨迹的时序场景分段

**理论基础**：人类或机器人探索环境时的运动模式与场景功能分区存在内在关联——停留环顾指示高信息密度区域，快速穿越对应过渡空间，视觉突变标志功能边界跨越。

**多源信号融合策略**：

| 信号类型 | 提取方式 | 语义含义 |
|---------|---------|---------|
| 运动模态信号 | 相邻帧位姿的欧氏距离与角度变化 | 运动速度极值点对应行为模式转换 |
| 视觉模态信号 | 相邻帧CLIP编码的余弦相似度 | 相似度骤降指示功能区域转换 |
| 语义模态信号 | 物体检测增量统计 + 空间分隔物体（门框/墙体）检测 | 新物体涌现峰值指示进入新区域 |

**输出**：将连续帧序列划分为语义连贯的局部片段，每个片段对应物理空间中相对独立的功能区域。

#### 模块2：多粒度场景描述生成

构建**全局-局部-物体**三级语义粒度的金字塔式描述体系：

| 层级 | 输入 | 输出内容 | 设计目标 |
|-----|------|---------|---------|
| 全局层级 | 完整物体类别分布 | 场景类型判定、主要物体构成、整体空间特征 | 以最小token消耗建立场景本质认知 |
| 局部层级 | 区域物体清单、空间关系、相对方位 | 区域功能定位、关键物体空间组织、可承载活动类型 | 建立特定区域的具象认知 |
| 物体层级 | 单个物体实例 | 空间定位（基于参照物的相对位置）、功能用途、视觉属性（颜色/材质/尺寸） | 构建结构化语义档案 |

**附加能力**：利用视觉语言模型为空间共现物体对生成开放词汇的细粒度关系描述。